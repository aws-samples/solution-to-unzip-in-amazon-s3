AWSTemplateFormatVersion: "2010-09-09"

Parameters:
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: The ID of the VPC where the Lambda function should be created

  SubnetIds:
    Type: List<AWS::EC2::Subnet::Id>
    Description: The list of Subnet IDs where the Lambda function should be created

  SecurityGroupIds:
    Type: List<AWS::EC2::SecurityGroup::Id>
    Description: The list of Security Group IDs to be associated with the Lambda function
Resources:
  LogsLogGroup00awsvendedlogsstatesmys3UnzipLogs00jsKZ1:
    UpdateReplacePolicy: "Retain"
    Type: "AWS::Logs::LogGroup"
    DeletionPolicy: "Delete"
    Properties:
      LogGroupClass: "STANDARD"
      LogGroupName: "/aws/vendedlogs/states/s3unzip-Logs"
      DataProtectionPolicy: {} 
  SSMDocument00s3unzipec200:
    UpdateReplacePolicy: "Retain"
    Type: "AWS::SSM::Document"
    DeletionPolicy: "Delete"
    Properties:
      DocumentFormat: "YAML"
      DocumentType: "Automation"
      Name: "s3unzipec2"
      Content: 
        schemaVersion: '0.3'
        description: |-
          ## Intent
            SOP to unzip file in S3. It launches EC2 instance that download the zipped file from S3 bucket, unzips the file and uploads the unzipped file to the user provided target S3 location

          ## Type
            Software

          ## Risk
            Small

          ## Requirements
            * S3
            * EC2

          ## Permission required for AutomationAssumeRole
          * ec2:RunInstances
          * ec2:DescribeInstanceStatus
          * ec2:TerminateInstances
          * s3:GetObject,
          * s3:GetObjectAttributes

          ## Supports Rollback
            No.

          ## Inputs
          ### SourceBucket
            * Description: (Required) The name of the S3 bucket that contains the zip file
            * Type: String
          ### SourceKey
            * Description: (Required) The key of the zipped file
            * Type: String
          ### TargetBucket:
            * Description: (Required) The S3 bucket where the unzipped files need to be stored
            * Type: String
          ### TargetPrefix:
            * Description: (Required) The prefix (folder) where the unzipped file need to be uploaded
            * Type: String
          ### OutputBucket:
            * Description: (Required) The S3 bucket where the EC2 instance will store the output logs
            * Type: String
          ### InstanceType:
            * Description: (Required) The type of instance to be launched for unzipped the file
            * Type: String
          ### SubnetId:
              *Description: The subnet where EC2 should be launched
              *Type: String
          ###SecurityGroupIds:
              *Description: Security Groups for the EC2 instance
              *Type: StringList



          ## Details of SSM Document steps:
          * RunScript_create_commands_for_ec2
          * LaunchInstance
          * WaitonEC2
          * CreateDirectory
          * CreateScript
          * UnzipFile
          * TerminateInstances
        assumeRole: !Join ["", ["arn:aws:iam::", !Ref 'AWS::AccountId', ":role/s3unzip-SSM-Role"]]
        parameters:
          SourceBucket:
            description: The name of the S3 bucket that contains the zip file
            type: String
            allowedPattern: ^[a-z0-9.-]{3,63}$
          OutputBucket:
            description: The S3 bucket where the EC2 instance will store the output logs
            type: String
            allowedPattern: ^[a-z0-9.-]{3,63}$
          TargetPrefix:
            description: The prefix (folder) where the unzipped file need to be uploaded
            type: String
            allowedPattern: ^[a-zA-Z0-9!_.*'()\-%@&=+/$,\s]+/?$
          SourceKey:
            description: The key of the zipped file
            type: String
            allowedPattern: ^[a-zA-Z0-9!_.*'()\-%@&=+/$,\s]+$
          TargetBucket:
            description: The S3 bucket where the unzipped files need to be stored
            type: String
            allowedPattern: ^[a-z0-9.-]{3,63}$
          InstanceType:
            description: The type of instance to be launched for unzipped the file
            type: String
            allowedPattern: ^(t2|t3|t3a|m4|m5|m5a|m5ad|m5d|m6g|m6gd|c4|c5|c5a|c5ad|c5d|c5n|c6g|c6gd|c6gn|r4|r5|r5a|r5ad|r5d|r5n|r6g|r6gd|x1|x1e|z1d|u-6tb1|u-8tb1|u-9tb1|u-12tb1|u-18tb1|u-24tb1|inf1)\.([a-z0-9]+)$
          SubnetId:
            type: String
            description: The subnet where EC2 should be launched
            allowedPattern: ^subnet-[0-9a-f]{8,17}$
          SecurityGroupIds:
            type: StringList
            description: Security Groups for the EC2 instance
            allowedPattern: ^(sg-[0-9a-f]{8,17})(,sg-[0-9a-f]{8,17})*$
        mainSteps:
          - description: This step will generate the commands that will be executed on the EC2 instance
            name: RunScript_create_commands_for_ec2
            action: aws:executeScript
            nextStep: LaunchInstance
            isEnd: false
            onCancel: Abort
            onFailure: Abort
            inputs:
              Script: |-
                import boto3
                import zipfile
                import io
                import datetime
                import math

                s3 = boto3.client('s3')
                ssm_client = boto3.client('ssm')

                def script_handler(events, context):
                  source_bucket = events['source_bucket']
                  source_key = events['source_key']
                  target_bucket = events['target_bucket']
                  target_prefix = events['target_prefix']
                  output_bucket = events['output_bucket']
                  execution_id = events['execution_id']
                  now = datetime.datetime.now()
                  current_date = now.strftime("%Y-%m-%d")
                  current_time = now.strftime("%H:%M:%S")
                  output_prefix = current_date + '/' + current_time 

                  target_prefix_empty = "false"
                  # Create a paginator to list objects in the target_bucket/target_prefix
                  paginator = s3.get_paginator('list_objects_v2')
                  page_iterator = paginator.paginate(Bucket=target_bucket, Prefix=target_prefix)

                  # Check if any objects are present in the bucket/prefix
                  for page in page_iterator:
                    if page.get('Contents', []):
                      target_prefix_empty = "true"
                      raise Exception(f"Target locaton s3://{target_bucket}/{target_prefix} is not empty. Cannot unzip to this location to prevent accidental overwrite of existing objects. Empty the target location and try again.")
                  
                  print(source_bucket, source_key, target_bucket, target_prefix, target_prefix_empty)  
                  ObjectSize = s3.head_object(Bucket=source_bucket, Key=source_key)['ContentLength']
                  print(ObjectSize)
                  VolumeSize = math.ceil(math.ceil(ObjectSize/(8*1024*1024*1024))*5)*8

                  # Define the parameter name for the latest AL2023 AMI ID
                  parameter_name = '/aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64'
                  response = ssm_client.get_parameter(Name=parameter_name)
                  latest_ami_id = response['Parameter']['Value']

                  if source_key.endswith('.zip'):
                    Command_unzip = f"unzip -d unzipped/ {source_key}"
                  elif source_key.endswith('.tar.gz') or source_key.endswith('.tgz'):
                    Command_unzip = f"tar -xvf {source_key} -C unzipped"
                  elif source_key.endswith('.gz'):
                    Command_unzip = f"gunzip -c {source_key} > unzipped/$(basename {source_key} .gz)"
                  elif source_key.endswith('tar.bz2') or source_key.endswith('.tbz'):
                    Command_unzip = f"tar -xjf {source_key} -C unzipped"
                  elif source_key.endswith('.bz2'):
                    Command_unzip = f"bunzip2 -c {source_key} > unzipped/$(basename {source_key} .bz2)"
                  elif source_key.endswith('tar.xz') or source_key.endswith('.txz'):
                    Command_unzip = f"tar -xJf {source_key} -C unzipped"
                  elif source_key.endswith('.xz'):
                    Command_unzip = f"unxz -c {source_key} > unzipped/$(basename {source_key} .xz)"
                  else:    
                    raise Exception(f"Error: Unsupported file type {source_bucket}/{source_key}. Currently only following formats are supported - zip, tar.gz, tgz, gz, tar.bz2, tbz, bz2, tar.xz, txz and xz")
                    
                  return {
                    "StatusCode": 200,
                    "VolumeSize": VolumeSize,
                    "Command_unzip": Command_unzip,
                    "OutputS3KeyPrefix": output_prefix,
                    "latest_ami_id": latest_ami_id,
                    "execution_id": execution_id
                  }
              Runtime: python3.9
              InputPayload:
                output_bucket: '{{ OutputBucket }}'
                source_bucket: '{{ SourceBucket }}'
                target_bucket: '{{ TargetBucket }}'
                source_key: '{{ SourceKey }}'
                target_prefix: '{{ TargetPrefix }}'
                execution_id: '{{ automation:EXECUTION_ID }}'
              Handler: script_handler
            outputs:
              - Type: Integer
                Name: VolumeSize
                Selector: $.Payload.VolumeSize
              - Type: String
                Name: Command_unzip
                Selector: $.Payload.Command_unzip
              - Type: String
                Name: OutputS3KeyPrefix
                Selector: $.Payload.OutputS3KeyPrefix
              - Type: String
                Name: latest_ami_id
                Selector: $.Payload.latest_ami_id
              - Type: String
                Name: execution_id
                Selector: $.Payload.execution_id
          - description: Launch the EC2 instance that will be used to unzip files
            name: LaunchInstance
            action: aws:runInstances
            nextStep: WaitOnEC2
            isEnd: false
            onCancel: step:TerminateInstances
            onFailure: step:TerminateInstances
            inputs:
              MaxInstanceCount: 1
              TagSpecifications:
                - ResourceType: instance
                  Tags:
                    - Value: permitted
                      Key: s3unzip
              ImageId: '{{ RunScript_create_commands_for_ec2.latest_ami_id }}'
              BlockDeviceMappings:
                - Ebs:
                    VolumeType: gp3
                    VolumeSize: '{{ RunScript_create_commands_for_ec2.VolumeSize }}'
                    Encrypted: true
                    KmsKeyId: alias/aws/ebs
                  DeviceName: /dev/xvda
              InstanceType: '{{ InstanceType }}'
              MinInstanceCount: 1
              IamInstanceProfileArn: !Join ["", ["arn:aws:iam::", !Ref 'AWS::AccountId', ":instance-profile/s3unzip-EC2-Role"]]
              SubnetId: '{{ SubnetId }}'
              SecurityGroupIds: '{{ SecurityGroupIds }}'
          - name: WaitOnEC2
            action: aws:waitForAwsResourceProperty
            timeoutSeconds: 300
            nextStep: UnzipFile
            isEnd: false
            onCancel: step:TerminateInstances
            onFailure: step:TerminateInstances
            inputs:
              PropertySelector: Reservations[0].Instances[0].State.Name
              DesiredValues:
                - running
              Service: ec2
              Api: DescribeInstances
              InstanceIds: '{{ LaunchInstance.InstanceIds }}'
          - description: ''
            name: UnzipFile
            action: aws:runCommand
            nextStep: Cleanup
            isEnd: false
            onCancel: step:TerminateInstances
            onFailure: step:TerminateInstances
            inputs:
              Parameters:
                commands:
                  - capture_status(){ if [ $command_exit_status -ne 0 ]; then echo "Command failed."; exit $command_exit_status; fi; }
                  - mkdir /home/{{ RunScript_create_commands_for_ec2.execution_id }}
                  - command_exit_status=$?; capture_status
                  - cd /home/{{ RunScript_create_commands_for_ec2.execution_id }}
                  - command_exit_status=$?; capture_status
                  - mkdir s3unzipdir
                  - command_exit_status=$?; capture_status
                  - cd s3unzipdir
                  - command_exit_status=$?; capture_status
                  - aws s3 cp s3://{{ SourceBucket }}/{{ SourceKey }} ./{{ SourceKey }} 1>/dev/null;
                  - command_exit_status=$?; capture_status
                  - mkdir unzipped
                  - command_exit_status=$?; capture_status
                  - '{{ RunScript_create_commands_for_ec2.Command_unzip }}'
                  - command_exit_status=$?; capture_status
                  - aws s3 cp ./unzipped s3://{{ OutputBucket }}/{{ TargetPrefix }} --recursive 1>/dev/null
                  - command_exit_status=$?; capture_status
                  - ''
              DocumentName: AWS-RunShellScript
              InstanceIds: '{{ LaunchInstance.InstanceIds }}'
          - name: Cleanup
            action: aws:runCommand
            nextStep: TerminateInstances
            isEnd: false
            onCancel: step:TerminateInstances
            onFailure: step:TerminateInstances
            inputs:
              Parameters:
                commands:
                  - rm -r /home/{{ RunScript_create_commands_for_ec2.execution_id }}
                  - command_exit_status=$?; if [ $command_exit_status -ne 0 ]; then echo "Command failed." ; exit $command_exit_status; fi;
              DocumentName: AWS-RunShellScript
              InstanceIds: '{{ LaunchInstance.InstanceIds }}'
          - description: Terminate the EC2 Instance
            name: TerminateInstances
            action: aws:executeAwsApi
            isEnd: true
            inputs:
              Service: ec2
              Api: TerminateInstances
              InstanceIds: '{{ LaunchInstance.InstanceIds }}'
  LambdaFunction00s3unzipsmallfiles004S7wS:
    UpdateReplacePolicy: "Retain"
    Type: "AWS::Lambda::Function"
    DeletionPolicy: "Delete"
    Properties:
      FunctionName: "s3unzip-small-files"
      Runtime: "python3.12"
      Handler: "index.lambda_handler"
      Role: !Join ["", ["arn:aws:iam::", !Ref 'AWS::AccountId', ":role/service-role/s3unzip-Lambda-Role"]]
      MemorySize: 10240
      Description: ""
      TracingConfig:
        Mode: "PassThrough"
      Timeout: 900
      RuntimeManagementConfig:
        UpdateRuntimeOn: "Auto"
      FileSystemConfigs: []
      LoggingConfig:
        LogFormat: "Text"
        LogGroup: "/aws/lambda/s3unzip-lambda-small-files"
      EphemeralStorage:
        Size: 10240
      Architectures:
      - "x86_64"
      VpcConfig:
        SecurityGroupIds: !Ref SecurityGroupIds
        SubnetIds: !Ref SubnetIds
      Code:
        ZipFile: |
          # !/usr/bin/python

          import boto3
          import io
          import datetime
          import math
          import os
          import re
          import zipfile
          import tarfile
          import gzip
          import bz2
          import lzma


          def lambda_handler(event, context):

            source_bucket = event['source_bucket']
            source_key = event['source_key']
            target_bucket = event['target_bucket']
            target_prefix = event['target_prefix']
            s3 = boto3.client('s3')

            target_prefix_empty = "false"
            # Create a paginator to list objects in the target_bucket/target_prefix
            paginator = s3.get_paginator('list_objects_v2')
            page_iterator = paginator.paginate(Bucket=target_bucket, Prefix=target_prefix)

            # Check if any objects are present in the bucket/prefix
            for page in page_iterator:
              if page.get('Contents', []):
                target_prefix_empty = "true"
                #raise Exception(f"Target locaton s3://{target_bucket}/{target_prefix} is not empty. Cannot unzip to this location to prevent accidental overwrite of existing objects. Empty the target location and try again.")
                return {'StatusCode' : 400,
                "body": f"Error: Target locaton s3://{target_bucket}/{target_prefix} is not empty. Cannot unzip to this location to prevent accidental overwrite of existing objects. Empty the target location and try again."
                }
                
            object_metadata = s3.head_object(Bucket=source_bucket, Key=source_key)
            ObjectSize = object_metadata['ContentLength']
            content_type = object_metadata['ContentType']
            
            if ObjectSize > 1000000000:
              #raise ValueError("Objects greater than 1GB cannot be unzipped using this Lambda function")
              return {'StatusCode' : 400,
              "body": "Error: Objects greater than 1GB cannot be unzipped using this Lambda function"
              }
            

            
            # Retrieve the encrypted compressed file from S3
            response = s3.get_object(Bucket=source_bucket, Key=source_key)
            compressed_data = response['Body'].read()
                
            # Determine the compression type and decompress the data
            decompressed_data = decompress_data(compressed_data, source_key)

            # Upload the decompressed files to the target S3 bucket with encryption

            s3 = boto3.client('s3')
            for filename, content in decompressed_data.items():
              target_key = f'{target_prefix}{filename}'
              s3.put_object(Bucket=target_bucket, Key=target_key, Body=content)
              
            return {
                "StatusCode": 200,
                "body": f"Extracted and uploaded files from {source_bucket}/{source_key} to {target_bucket}/{target_prefix}"
              }

          def decompress_data(data, source_key):
              source_file_name = source_key.split('/')[-1]
              if source_key.endswith('.zip'):
                  return decompress_zip(data)
              elif source_key.endswith('.tar.gz') or source_key.endswith('.tgz'):
                  return decompress_tar_gz(data)
              elif source_key.endswith('.gz'):
                  return decompress_gz(data, source_file_name[:-3])
              elif source_key.endswith('tar.bz2') or source_key.endswith('.tbz'):
                  return decompress_tar_bz2(data)
              elif source_key.endswith('.bz2'):
                  return decompress_bz2(data, source_file_name[:-4])
              elif source_key.endswith('tar.xz') or source_key.endswith('.txz'):
                  return decompress_tar_xz(data)
              elif source_key.endswith('.xz'):
                  return decompress_xz(data, source_file_name[:-3])
              else:
                return {'StatusCode' : 400,
                  "body": f"Error: Unsupported file type {source_bucket}/{source_key}. Currently only following formats are supported - zip, tar.gz, tgz, gz, tar.bz2, tbz, bz2, tar.xz, txz and xz"
                }

          def decompress_zip(data):
              with zipfile.ZipFile(io.BytesIO(data), 'r') as zip_file:
                  return {name: zip_file.read(name) for name in zip_file.namelist()}

          def decompress_tar_gz(data):
              with tarfile.open(fileobj=io.BytesIO(data), mode='r:gz') as tar_file:
                  return {member.name: tar_file.extractfile(member).read() for member in tar_file.getmembers() if not member.isdir()}

          def decompress_gz(data, target_file_name):
              with gzip.GzipFile(fileobj=io.BytesIO(data), mode='rb') as gz_file:
                  return {target_file_name: gz_file.read()}

          def decompress_tar_bz2(data):
              with tarfile.open(fileobj=io.BytesIO(data), mode='r:bz2') as tar_file:
                  return {member.name: tar_file.extractfile(member).read() for member in tar_file.getmembers() if not member.isdir()}

          def decompress_bz2(data, target_file_name):
              return {target_file_name: bz2.decompress(data)}

          def decompress_tar_xz(data):
              with tarfile.open(fileobj=io.BytesIO(data), mode='r:xz') as tar_file:
                  return {member.name: tar_file.extractfile(member).read() for member in tar_file.getmembers() if not member.isdir()}


          def decompress_xz(data, target_file_name):
              return {target_file_name: lzma.decompress(data)}
  StepFunctionsStateMachine00stateMachinemys3Unzip00w146u:
    UpdateReplacePolicy: "Retain"
    Type: "AWS::StepFunctions::StateMachine"
    DeletionPolicy: "Delete"
    Properties:
      DefinitionString:  !Sub
        - |-
          {
            "Comment": "A description of my state machine",
            "StartAt": "ListObjectsV2: Is Target Location Empty",
            "States": {
              "ListObjectsV2: Is Target Location Empty": {
                "Type": "Task",
                "Parameters": {
                  "Bucket.$": "$.target_bucket",
                  "Prefix.$": "$.target_prefix"
                },
                "Resource": "arn:aws:states:::aws-sdk:s3:listObjectsV2",
                "Next": "Choice: Target location empty?",
                "ResultSelector": {
                  "TargetKeyCount.$": "$.KeyCount"
                },
                "ResultPath": "$.TargetLocation"
              },
              "Choice: Target location empty?": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.TargetLocation.TargetKeyCount",
                    "NumericGreaterThan": 0,
                    "Next": "Fail: Target location is not empty"
                  }
                ],
                "Default": "S3: GetObjectAttributes  - Get Compressed File Size"
              },
              "Fail: Target location is not empty": {
                "Type": "Fail"
              },
              "S3: GetObjectAttributes  - Get Compressed File Size": {
                "Type": "Task",
                "Next": "Choice: Lambda or SSM Document",
                "Parameters": {
                  "Bucket.$": "$.source_bucket",
                  "Key.$": "$.source_key",
                  "ObjectAttributes": [
                    "ObjectSize"
                  ]
                },
                "Resource": "arn:aws:states:::aws-sdk:s3:getObjectAttributes",
                "ResultPath": "$.ObjectAttributes"
              },
              "Choice: Lambda or SSM Document": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.ObjectAttributes.ObjectSize",
                    "NumericLessThan": 1000000000,
                    "Next": "Lambda Invoke Unzip Small Files"
                  }
                ],
                "Default": "StartAutomationExecution: Execute SSM Document"
              },
              "StartAutomationExecution: Execute SSM Document": {
                "Type": "Task",
                "Next": "GetAutomationExecution: Check SSM Document Execution Status",
                "Parameters": {
                  "DocumentName": "s3unzipec2",
                  "Parameters": {
                    "SourceBucket.$": "States.Array($.source_bucket)",
                    "SourceKey.$": "States.Array($.source_key)",
                    "TargetBucket.$": "States.Array($.target_bucket)",
                    "TargetPrefix.$": "States.Array($.target_prefix)",
                    "OutputBucket.$": "States.Array($.output_bucket)",
                    "InstanceType.$": "States.Array($.instance_type)",
                    "SubnetId.$": "States.Array($.SubnetId)",
                    "SecurityGroupIds.$": "States.Array($.SecurityGroupIds)"
                  }
                },
                "Resource": "arn:aws:states:::aws-sdk:ssm:startAutomationExecution",
                "ResultPath": "$.DocumentExecutionPayload"
              },
              "GetAutomationExecution: Check SSM Document Execution Status": {
                "Type": "Task",
                "Next": "Choice: AutomationExecution Status",
                "Parameters": {
                  "AutomationExecutionId.$": "$.DocumentExecutionPayload.AutomationExecutionId"
                },
                "Resource": "arn:aws:states:::aws-sdk:ssm:getAutomationExecution",
                "ResultPath": "$.AutomationExecution",
                "ResultSelector": {
                  "AutomationExecutionStatus.$": "$.AutomationExecution.AutomationExecutionStatus"
                }
              },
              "Choice: AutomationExecution Status": {
                "Type": "Choice",
                "Choices": [
                  {
                    "And": [
                      {
                        "Not": {
                          "Variable": "$.AutomationExecution.AutomationExecutionStatus",
                          "StringEquals": "Success"
                        }
                      },
                      {
                        "Not": {
                          "Variable": "$.AutomationExecution.AutomationExecutionStatus",
                          "StringEquals": "Failed"
                        }
                      },
                      {
                        "Not": {
                          "Variable": "$.AutomationExecution.AutomationExecutionStatus",
                          "StringEquals": "Cancelled"
                        }
                      },
                      {
                        "Not": {
                          "Variable": "$.AutomationExecution.AutomationExecutionStatus",
                          "StringEquals": "TimedOut"
                        }
                      }
                    ],
                    "Next": "Wait for AutomationExecution to Complete"
                  }
                ],
                "Default": "Pass: SSM Document Execution Completed"
              },
              "Pass: SSM Document Execution Completed": {
                "Type": "Pass",
                "ResultPath": "$.PassThrough",
                "Next": "Choice: DocumentExecutionStatus"
              },
              "Choice: DocumentExecutionStatus": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.AutomationExecution.AutomationExecutionStatus",
                    "StringEquals": "Success",
                    "Next": "Pass: DocumentExecutionSuccessful"
                  }
                ],
                "Default": "Fail: DocumentExecutionFailire"
              },
              "Pass: DocumentExecutionSuccessful": {
                "Type": "Pass",
                "End": true
              },
              "Fail: DocumentExecutionFailire": {
                "Type": "Fail"
              },
              "Wait for AutomationExecution to Complete": {
                "Type": "Wait",
                "Seconds": 60,
                "Next": "GetAutomationExecution: Check SSM Document Execution Status"
              },
              "Lambda Invoke Unzip Small Files": {
                "Type": "Task",
                "Resource": "arn:aws:states:::lambda:invoke",
                "Parameters": {
                  "Payload.$": "$",
                  "FunctionName": "${LambdaFunctionArn}"
                },
                "Retry": [
                  {
                    "ErrorEquals": [
                      "Lambda.ServiceException",
                      "Lambda.AWSLambdaException",
                      "Lambda.SdkClientException",
                      "Lambda.TooManyRequestsException"
                    ],
                    "IntervalSeconds": 1,
                    "MaxAttempts": 3,
                    "BackoffRate": 2
                  }
                ],
                "ResultPath": "$.LambdaOutput",
                "Next": "Choice: LambdaExecutionStatus",
                "ResultSelector": {
                  "StatusCode.$": "$.Payload.StatusCode",
                  "body.$": "$.Payload.body"
                }
              },
              "Choice: LambdaExecutionStatus": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.LambdaOutput.StatusCode",
                    "NumericEquals": 200,
                    "Next": "Pass: LambdaExecutionSuccessful"
                  }
                ],
                "Default": "Fail: LambdaExecutionFailure"
              },
              "Pass: LambdaExecutionSuccessful": {
                "Type": "Pass",
                "End": true
              },
              "Fail: LambdaExecutionFailure": {
                "Type": "Fail",
                "ErrorPath": "$.LambdaOutput.body",
                "CausePath": "$.source_key"
              }
            }
          }
        - { LambdaFunctionArn: !GetAtt LambdaFunction00s3unzipsmallfiles004S7wS.Arn}

      LoggingConfiguration:
        IncludeExecutionData: true
        Destinations:
        - CloudWatchLogsLogGroup:
            LogGroupArn: !GetAtt LogsLogGroup00awsvendedlogsstatesmys3UnzipLogs00jsKZ1.Arn
        Level: "ALL"
      StateMachineName: "s3unzip-sf"
      RoleArn: !Join ["", ["arn:aws:iam::", !Ref 'AWS::AccountId', ":role/service-role/s3unzip-StepFunctions-Role"]]
      StateMachineType: "STANDARD"
      TracingConfiguration:
        Enabled: false
